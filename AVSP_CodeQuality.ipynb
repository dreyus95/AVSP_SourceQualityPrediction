{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nikola/Faks/Diplomski/DrugiSemestar/AVSP/LabAssignment/AVSP_SourceQualityPrediction/CodeJamCrawler/dataset/12_2091_53.cpp,1,35,17,33,0,2,16.50,0.00,16.50,0.94,33,0,2\r\n",
      "\n",
      "csvs/08_10063_50.csv;1;61;61.000;12;12.000;0;0.000;******;******;0;0.000;0;0.000;0;0.000;4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linesCodeAnalyzer = None\n",
    "with open('CodeJamCrawler/dataset/code_analyzer_output/dataset_analyzed.csv', 'r') as f:\n",
    "    linesCodeAnalyzer = f.readlines()\n",
    "codeAnalyzerHeader = linesCodeAnalyzer[0]\n",
    "linesCodeAnalyzer = linesCodeAnalyzer[1:]\n",
    "print linesCodeAnalyzer[0]\n",
    "\n",
    "linesCccc = None\n",
    "with open('outputCleared.txt', 'r') as f:\n",
    "    linesCccc = f.readlines()\n",
    "    \n",
    "print linesCccc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_name(line, splitter):\n",
    "    entries = line.split(splitter)\n",
    "    file_name = entries[0].split('/')[-1]\n",
    "    return file_name.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_2091_53\n",
      "08_10063_50\n"
     ]
    }
   ],
   "source": [
    "print get_file_name(linesCodeAnalyzer[0], ',')\n",
    "print get_file_name(linesCccc[0], ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# removing all the entries that aren't existing in outputCleared\n",
    "cpp_files_only = []\n",
    "for i in range(len(linesCodeAnalyzer)):\n",
    "    if i % 1000 == 0:\n",
    "        print i\n",
    "    other = linesCodeAnalyzer[i]\n",
    "    file_name_other = get_file_name(other, ',')\n",
    "    found = False\n",
    "    for cleared in linesCccc:\n",
    "        file_name_cleared = get_file_name(cleared, ';')\n",
    "        if file_name_cleared == file_name_other:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        continue\n",
    "    cpp_files_only.append(file_name_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_2091_53\n"
     ]
    }
   ],
   "source": [
    "print cpp_files_only[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code anal #File Name,Files,Lines,AVG Len,Code,Comments,White SP,Cd/Cm+WS,Cd/Cm,Cd/WS,% Code,Cd/File,Cm/File,WS/File,\r\n",
      "\n",
      "cccc filename;number_of_modules;lines_of_code;lines_of_code_per_module;McCabes_cyclomatic_complexity;McCabes_cyclomatic_complexity_per_module;lines_of_comment;lines_of_comment_per_module;lines_of_code_per_line_of_comment;McCabes_cyclomatic_complexity_per_line_of_comment;IF4;IF4_per_module;IF4_visible;IF4_visible_per_module;IF4_concrete;IF4_concrete;rejected_lines_of_code\n"
     ]
    }
   ],
   "source": [
    "print 'code anal', codeAnalyzerHeader\n",
    "print 'cccc', 'filename;number_of_modules;lines_of_code;lines_of_code_per_module;McCabes_cyclomatic_complexity;McCabes_cyclomatic_complexity_per_module;lines_of_comment;lines_of_comment_per_module;lines_of_code_per_line_of_comment;McCabes_cyclomatic_complexity_per_line_of_comment;IF4;IF4_per_module;IF4_visible;IF4_visible_per_module;IF4_concrete;IF4_concrete;rejected_lines_of_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_cccc(cccc_line):\n",
    "    name = get_file_name(cccc_line, ';')\n",
    "    res = name.split('_')[-1]\n",
    "    features = []\n",
    "    for num in cccc_line.split(';')[1:]:\n",
    "        if num == '******' or num == '------':\n",
    "            num = '0.0'\n",
    "        try:\n",
    "            features.append(float(num))\n",
    "        except ValueError:\n",
    "            print num\n",
    "            break\n",
    "    return name, features, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_code_analyzer(code_anal_line):\n",
    "    name = get_file_name(code_anal_line, ',')\n",
    "    res = name.split('_')[-1]\n",
    "    features = []\n",
    "    for num in code_anal_line.split(',')[1:]:\n",
    "        try:\n",
    "            features.append(float(num))\n",
    "        except ValueError:\n",
    "            print num\n",
    "            break\n",
    "    return name, features, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cccc line vec ('08_10063_50', [1.0, 61.0, 61.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], '50')\n",
      "code line vec ('12_2091_53', [1.0, 35.0, 17.0, 33.0, 0.0, 2.0, 16.5, 0.0, 16.5, 0.94, 33.0, 0.0, 2.0], '53')\n"
     ]
    }
   ],
   "source": [
    "print 'cccc line vec', parse_cccc(linesCccc[0])\n",
    "print 'code line vec', parse_code_analyzer(linesCodeAnalyzer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpp_files_map = set(cpp_files_only)\n",
    "src_vec_map = {}\n",
    "\n",
    "for cccc_line in linesCccc:\n",
    "    name, features, res = parse_cccc(cccc_line)\n",
    "    src_vec_map[name] = [features]\n",
    "\n",
    "for code_anal_line in linesCodeAnalyzer:\n",
    "    name, features, res = parse_code_analyzer(code_anal_line)\n",
    "    if name in cpp_files_map:\n",
    "        src_vec_map[name].append(features)\n",
    "        src_vec_map[name].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 61.0, 61.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], [1.0, 64.0, 12.0, 63.0, 0.0, 1.0, 63.0, 0.0, 63.0, 0.98, 63.0, 0.0, 1.0], '50']\n"
     ]
    }
   ],
   "source": [
    "print src_vec_map[parse_cccc(linesCccc[0])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_numpy_vec(values):\n",
    "    l1 = len(values[0])\n",
    "    l2 = len(values[1])\n",
    "    l3 = 1\n",
    "    vec_len = l1 + l2 + l3\n",
    "    vec = np.zeros((l1 + l2 + l3, 1))\n",
    "    vec_pos = 0\n",
    "    for i in range(l1):\n",
    "        vec[vec_pos] = values[0][i]\n",
    "        vec_pos += 1\n",
    "    for i in range(l2):\n",
    "        vec[vec_pos] = values[1][i]\n",
    "        vec_pos += 1\n",
    "    vec[vec_pos] = values[2]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(create_numpy_vec(src_vec_map[parse_cccc(linesCccc[0])[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def load_dataset(src_vec_map):\n",
    "    vec = src_vec_map[src_vec_map.keys()[0]]\n",
    "    dim_vec = len(create_numpy_vec(vec))\n",
    "    cnt_files = len(src_vec_map)\n",
    "    dataset_list = []\n",
    "    pos = 0\n",
    "    for k in src_vec_map:\n",
    "        dataset_list.append(create_numpy_vec(src_vec_map[k]))\n",
    "    dataset = np.array(dataset_list)\n",
    "    dataset = dataset.reshape((dataset.shape[0], dataset.shape[1]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(src_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19153, 30)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19153,)\n",
      "(19153, 29)\n"
     ]
    }
   ],
   "source": [
    "dim = dataset.shape[1]\n",
    "\n",
    "y = dataset[:,dim-1]\n",
    "print y.shape\n",
    "X = dataset[:, 0:dim-1]\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_same_cols(X):\n",
    "    cnt_cols = X.shape[1]\n",
    "    X_reduced = []\n",
    "    \n",
    "    for i in range(cnt_cols):\n",
    "        col = dataset[:,i]\n",
    "        notInside = True\n",
    "        for j in range(len(X_reduced)):\n",
    "            if (col == X_reduced[j]).all():\n",
    "                notInside = False\n",
    "        \n",
    "        if notInside:\n",
    "            X_reduced.append(col)\n",
    "\n",
    "    return np.array(X_reduced).T\n",
    "\n",
    "X = remove_same_cols(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components='mle', random_state=None,\n",
       "  svd_solver='full', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components='mle', svd_solver='full')\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 25)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.transform(X[0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dataset_to_file(file_name_X, file_name_y, X, y):\n",
    "    np.savetxt(file_name_X, X)\n",
    "    np.savetxt(file_name_y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_dataset_to_file('X.txt', 'y.txt', X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_dataset_from_file(features, results):\n",
    "    return np.loadtxt(features), np.loadtxt(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19153, 26) (19153,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset_from_file('X.txt', 'y.txt')\n",
    "print X.shape, y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
