{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0_14_16505_55.cpp,1,49,13,47,0,2,23.50,0.00,23.50,0.96,47,0,2\n",
      "\n",
      "0.0_14_16505_55.csv;1;43;43.000;12;12.000;0;0.000;******;******;0;0.000;0;0.000;0;0.000;3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linesCodeAnalyzer = None\n",
    "with open('CodeJamCrawler/dataset_csvs/code_analyzer_out_sorted.csv', 'r') as f:\n",
    "    linesCodeAnalyzer = f.readlines()\n",
    "    \n",
    "codeAnalyzerHeader = linesCodeAnalyzer[0]\n",
    "linesCodeAnalyzer = linesCodeAnalyzer[1:]\n",
    "\n",
    "linesCccc = None\n",
    "with open('CodeJamCrawler/dataset_csvs/cccc_cleared.csv', 'r') as f:\n",
    "    linesCccc = f.readlines()\n",
    "    \n",
    "ccccHeader = linesCccc[0]\n",
    "linesCccc = linesCccc[1:]\n",
    "\n",
    "print (linesCodeAnalyzer[0])\n",
    "print (linesCccc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_name(line, splitter):\n",
    "    entries = line.split(splitter)\n",
    "    file_name = entries[0][0:-4]\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0_14_16505_55\n",
      "0.0_14_16505_55\n"
     ]
    }
   ],
   "source": [
    "print (get_file_name(linesCodeAnalyzer[0], ','))\n",
    "print (get_file_name(linesCccc[0], ';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "Number of cpp files: 16521\n"
     ]
    }
   ],
   "source": [
    "# removing all the entries that aren't existing in outputCleared\n",
    "cpp_files_only = []\n",
    "for i in range(len(linesCodeAnalyzer)):\n",
    "    if i % 1000 == 0:\n",
    "        print (i)\n",
    "        \n",
    "    other = linesCodeAnalyzer[i]\n",
    "    file_name_other = get_file_name(other, ',')\n",
    "    \n",
    "    found = False\n",
    "    for cleared in linesCccc:\n",
    "        file_name_cleared = get_file_name(cleared, ';')\n",
    "        if file_name_cleared == file_name_other:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        continue\n",
    "    cpp_files_only.append(file_name_other)\n",
    "    \n",
    "print (\"Number of cpp files:\", len(cpp_files_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0_14_16505_55\n"
     ]
    }
   ],
   "source": [
    "print (cpp_files_only[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code analyzer output: #File Name,Files,Lines,AVG Len,Code,Comments,White SP,Cd/Cm+WS,Cd/Cm,Cd/WS,% Code,Cd/File,Cm/File,WS/File,\n",
      "\n",
      "CCCC analyzer output: #filename;number_of_modules;lines_of_code;lines_of_code_per_module;McCabes_cyclomatic_complexity;McCabes_cyclomatic_complexity_per_module;lines_of_comment;lines_of_comment_per_module;lines_of_code_per_line_of_comment;McCabes_cyclomatic_complexity_per_line_of_comment;IF4;IF4_per_module;IF4_visible;IF4_visible_per_module;IF4_concrete;IF4_concrete;rejected_lines_of_code\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Code analyzer output:', codeAnalyzerHeader)\n",
    "print ('CCCC analyzer output:', ccccHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_cccc(cccc_line):\n",
    "    name = get_file_name(cccc_line, ';')\n",
    "    res = name.split('_')[-1]\n",
    "    author = name.split('_')[0]\n",
    "    features = []\n",
    "    for num in cccc_line.split(';')[1:]:\n",
    "        if num == '******' or num == '------':\n",
    "            num = '0.0'\n",
    "        try:\n",
    "            features.append(float(num))\n",
    "        except ValueError:\n",
    "            print (num)\n",
    "            break\n",
    "    return author, features, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_code_analyzer(code_anal_line):\n",
    "    name = get_file_name(code_anal_line, ',')\n",
    "    res = name.split('_')[-1]\n",
    "    author = name.split('_')[0]\n",
    "    features = []\n",
    "    for num in code_anal_line.split(',')[1:]:\n",
    "        try:\n",
    "            features.append(float(num))\n",
    "        except ValueError:\n",
    "            print (num)\n",
    "            break\n",
    "    return author, features, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cccc line vec ('0.0', [1.0, 43.0, 43.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], '55')\n",
      "code line vec ('0.0', [1.0, 49.0, 13.0, 47.0, 0.0, 2.0, 23.5, 0.0, 23.5, 0.96, 47.0, 0.0, 2.0], '55')\n"
     ]
    }
   ],
   "source": [
    "print ('cccc line vec', parse_cccc(linesCccc[0]))\n",
    "print ('code line vec', parse_code_analyzer(linesCodeAnalyzer[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpp_files_map = set()\n",
    "\n",
    "for n in cpp_files_only:\n",
    "    cpp_files_map.add(n.split('_')[0])\n",
    "\n",
    "src_vec_map = {}\n",
    "\n",
    "for cccc_line in linesCccc:\n",
    "    name, features, res = parse_cccc(cccc_line)\n",
    "    if name not in src_vec_map:\n",
    "        src_vec_map[name] = [(features,res)]\n",
    "    else:\n",
    "        src_vec_map[name].append((features, res))\n",
    "\n",
    "for code_anal_line in linesCodeAnalyzer:\n",
    "    name, features, res = parse_code_analyzer(code_anal_line)\n",
    "    if name in cpp_files_map:\n",
    "        src_vec_map[name].append((features, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "([1.0, 74.0, 74.0, 16.0, 16.0, 47.0, 47.0, 1.574, 0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], '55')\n",
      "([1.0, 74.0, 74.0, 16.0, 16.0, 47.0, 47.0, 1.574, 0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], '55')\n",
      "([1.0, 85.0, 85.0, 18.0, 18.0, 47.0, 47.0, 1.809, 0.383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], '55')\n",
      "([1.0, 47.0, 47.0, 10.0, 10.0, 46.0, 46.0, 1.022, 0.217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], '55')\n",
      "([1.0, 28.0, 28.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], '55')\n",
      "([1.0, 55.0, 55.0, 16.0, 16.0, 3.0, 3.0, 18.333, 5.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], '6')\n",
      "([1.0, 97.0, 97.0, 18.0, 18.0, 1.0, 1.0, 97.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0], '20')\n",
      "([1.0, 97.0, 97.0, 18.0, 18.0, 1.0, 1.0, 97.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0], '20')\n",
      "([1.0, 63.0, 63.0, 18.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], '40')\n",
      "([1.0, 63.0, 63.0, 18.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], '40')\n",
      "([1.0, 115.0, 115.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0], '40')\n",
      "([1.0, 46.0, 46.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], '40')\n",
      "([1.0, 52.0, 52.0, 31.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], '60')\n",
      "([1.0, 44.0, 44.0, 14.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], '60')\n",
      "([1.0, 44.0, 44.0, 14.0, 14.0, 1.0, 1.0, 44.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], '60')\n",
      "([1.0, 57.0, 57.0, 10.0, 10.0, 1.0, 1.0, 57.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0], '60')\n",
      "([1.0, 54.0, 54.0, 10.0, 10.0, 3.0, 3.0, 18.0, 3.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0], '60')\n",
      "([1.0, 61.0, 61.0, 11.0, 11.0, 1.0, 1.0, 61.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0], '53')\n",
      "([1.0, 34.0, 34.0, 6.0, 6.0, 5.0, 5.0, 6.8, 1.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0], '53')\n",
      "([1.0, 94.0, 94.0, 25.0, 25.0, 1.0, 1.0, 94.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], '53')\n",
      "([1.0, 94.0, 94.0, 25.0, 25.0, 1.0, 1.0, 94.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0], '53')\n",
      "([1.0, 91.0, 91.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], '80')\n",
      "([1.0, 91.0, 91.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], '80')\n",
      "([1.0, 53.0, 53.0, 24.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], '80')\n",
      "([1.0, 53.0, 53.0, 24.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], '80')\n",
      "([1.0, 67.0, 67.0, 18.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], '80')\n",
      "([1.0, 149.0, 15.0, 99.0, 47.0, 3.0, 1.98, 2.11, 33.0, 0.66, 99.0, 47.0, 3.0], '55')\n",
      "([1.0, 149.0, 15.0, 99.0, 47.0, 3.0, 1.98, 2.11, 33.0, 0.66, 99.0, 47.0, 3.0], '55')\n",
      "([1.0, 160.0, 16.0, 110.0, 47.0, 3.0, 2.2, 2.34, 36.67, 0.69, 110.0, 47.0, 3.0], '55')\n",
      "([1.0, 121.0, 16.0, 72.0, 46.0, 3.0, 1.47, 1.57, 24.0, 0.6, 72.0, 46.0, 3.0], '55')\n",
      "([1.0, 54.0, 16.0, 53.0, 0.0, 1.0, 53.0, 0.0, 53.0, 0.98, 53.0, 0.0, 1.0], '55')\n",
      "([1.0, 85.0, 16.0, 81.0, 3.0, 1.0, 20.25, 27.0, 81.0, 0.95, 81.0, 3.0, 1.0], '6')\n",
      "([1.0, 127.0, 14.0, 123.0, 1.0, 3.0, 30.75, 123.0, 41.0, 0.97, 123.0, 1.0, 3.0], '20')\n",
      "([1.0, 127.0, 14.0, 123.0, 1.0, 3.0, 30.75, 123.0, 41.0, 0.97, 123.0, 1.0, 3.0], '20')\n",
      "([1.0, 92.0, 14.0, 89.0, 0.0, 3.0, 29.67, 0.0, 29.67, 0.97, 89.0, 0.0, 3.0], '40')\n",
      "([1.0, 92.0, 14.0, 89.0, 0.0, 3.0, 29.67, 0.0, 29.67, 0.97, 89.0, 0.0, 3.0], '40')\n",
      "([1.0, 146.0, 14.0, 141.0, 0.0, 5.0, 28.2, 0.0, 28.2, 0.97, 141.0, 0.0, 5.0], '40')\n",
      "([1.0, 75.0, 15.0, 72.0, 0.0, 3.0, 24.0, 0.0, 24.0, 0.96, 72.0, 0.0, 3.0], '40')\n",
      "([1.0, 85.0, 19.0, 82.0, 0.0, 3.0, 27.33, 0.0, 27.33, 0.96, 82.0, 0.0, 3.0], '60')\n",
      "([1.0, 77.0, 18.0, 74.0, 0.0, 3.0, 24.67, 0.0, 24.67, 0.96, 74.0, 0.0, 3.0], '60')\n",
      "([1.0, 78.0, 18.0, 74.0, 1.0, 3.0, 18.5, 74.0, 24.67, 0.95, 74.0, 1.0, 3.0], '60')\n",
      "([1.0, 91.0, 18.0, 86.0, 1.0, 4.0, 17.2, 86.0, 21.5, 0.95, 86.0, 1.0, 4.0], '60')\n",
      "([1.0, 90.0, 17.0, 83.0, 3.0, 4.0, 11.86, 27.67, 20.75, 0.92, 83.0, 3.0, 4.0], '60')\n",
      "([1.0, 96.0, 25.0, 91.0, 1.0, 4.0, 18.2, 91.0, 22.75, 0.95, 91.0, 1.0, 4.0], '53')\n",
      "([1.0, 72.0, 20.0, 64.0, 5.0, 4.0, 7.11, 12.8, 16.0, 0.89, 64.0, 5.0, 4.0], '53')\n",
      "([1.0, 128.0, 18.0, 124.0, 1.0, 3.0, 31.0, 124.0, 41.33, 0.97, 124.0, 1.0, 3.0], '53')\n",
      "([1.0, 128.0, 18.0, 124.0, 1.0, 3.0, 31.0, 124.0, 41.33, 0.97, 124.0, 1.0, 3.0], '53')\n",
      "([1.0, 79.0, 23.0, 75.0, 1.0, 3.0, 18.75, 75.0, 25.0, 0.95, 75.0, 1.0, 3.0], '14')\n",
      "([1.0, 79.0, 23.0, 75.0, 1.0, 3.0, 18.75, 75.0, 25.0, 0.95, 75.0, 1.0, 3.0], '14')\n",
      "([1.0, 124.0, 20.0, 121.0, 0.0, 3.0, 40.33, 0.0, 40.33, 0.98, 121.0, 0.0, 3.0], '80')\n",
      "([1.0, 124.0, 20.0, 121.0, 0.0, 3.0, 40.33, 0.0, 40.33, 0.98, 121.0, 0.0, 3.0], '80')\n",
      "([1.0, 86.0, 19.0, 83.0, 0.0, 3.0, 27.67, 0.0, 27.67, 0.97, 83.0, 0.0, 3.0], '80')\n",
      "([1.0, 86.0, 19.0, 83.0, 0.0, 3.0, 27.67, 0.0, 27.67, 0.97, 83.0, 0.0, 3.0], '80')\n",
      "([1.0, 101.0, 19.0, 97.0, 0.0, 4.0, 24.25, 0.0, 24.25, 0.96, 97.0, 0.0, 4.0], '80')\n"
     ]
    }
   ],
   "source": [
    "print (len(src_vec_map[\"4TShirt\"]))\n",
    "for v in src_vec_map[\"4TShirt\"] :\n",
    "    print (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1825\n",
      "Number of csvs:  36221\n"
     ]
    }
   ],
   "source": [
    "print (len(src_vec_map))\n",
    "csvs_count = 0\n",
    "for k in src_vec_map:\n",
    "    csvs_count += len(src_vec_map[k])\n",
    "    \n",
    "print (\"Number of csvs: \", csvs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def load_dataset(src_vec_map):\n",
    "    dataset_list = []\n",
    "    \n",
    "    for k in src_vec_map:\n",
    "        i = 0\n",
    "        half_list = int(len(src_vec_map[k])/2)\n",
    "        \n",
    "        while i < half_list :\n",
    "            label = src_vec_map[k][i][1]\n",
    "            #print(label)\n",
    "            l1 = np.asarray(src_vec_map[k][i][0])\n",
    "            l2 = np.asarray(src_vec_map[k][i+half_list][0])\n",
    "            #print (l1.shape, l2.shape)\n",
    "            l = np.concatenate((l1, l2), axis=0)\n",
    "            i += 1\n",
    "            \n",
    "            # pojma nemam zašto se ovo događa - goran\n",
    "            if l.size != 29:\n",
    "                continue\n",
    "            dataset_list.append((l, (k, label)))\n",
    "            \n",
    "    dataset = np.array(dataset_list)\n",
    "    dataset = dataset.reshape((dataset.shape[0], dataset.shape[1]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17344, 2) NOTE : first dimension should be same as 18788/2\n",
      "\n",
      "\n",
      "('masscot', '25')\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(src_vec_map)\n",
    "print (dataset.shape, \"NOTE : first dimension should be same as 18788/2\\n\\n\")\n",
    "print (dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_author_features_and_scores(author_name, dataset):\n",
    "    codes = []\n",
    "    scores = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        if item[1][0] == author_name:\n",
    "            codes.append(item[0])\n",
    "            scores.append(item[1][1])\n",
    "            \n",
    "    return (codes, scores)  \n",
    "\n",
    "def create_correct_np_array(data_list):\n",
    "    arr = np.array([])\n",
    "    arr = np.hstack((arr, np.array(data_list[0])))\n",
    "\n",
    "    for i in range(1, len(data_list)):\n",
    "        arr = np.vstack((arr, np.array(data_list[i])))\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n",
      "525\n"
     ]
    }
   ],
   "source": [
    "# training and test authors, cca 70-30 omjer\n",
    "author_names = list(src_vec_map.keys())\n",
    "\n",
    "train_authors = author_names[0:1300]\n",
    "test_authors = author_names[1300:]\n",
    "\n",
    "print(len(train_authors))\n",
    "print(len(test_authors))\n",
    "\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for author in train_authors:\n",
    "    codes, scores = get_author_features_and_scores(author, dataset)\n",
    "    X_train_list.extend(codes)\n",
    "    y_train_list.extend(scores)\n",
    "    \n",
    "for author in test_authors:\n",
    "    codes, scores = get_author_features_and_scores(author, dataset)\n",
    "    X_test_list.extend(codes)\n",
    "    y_test_list.extend(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_TRAIN\n",
      "\n",
      "\n",
      "X_TEST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iz nekog razloga svi ovi kodovi imaju više značajki nego što bi trebali\n",
    "print(\"X_TRAIN\\n\")\n",
    "for i in range(1, len(X_train_list)):\n",
    "    if len (X_train_list[i]) != 29:\n",
    "        print (i, \"Broj značajki:\", len (X_train_list[i]))\n",
    "\n",
    "print(\"\\nX_TEST\\n\")\n",
    "for i in range(1, len(X_train_list)):\n",
    "    if len (X_train_list[i]) != 29:\n",
    "        print (i, \"Broj značajki:\", len (X_train_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12306, 29)\n",
      "(5038, 29)\n",
      "(12306, 1)\n",
      "(5038, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = create_correct_np_array(X_train_list)\n",
    "X_test = create_correct_np_array(X_test_list)\n",
    "y_train = create_correct_np_array(y_train_list)\n",
    "y_test = create_correct_np_array(y_test_list)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Files', 'Lines', 'AVG Len', 'Code', 'Comments', 'White SP', 'Cd/Cm+WS', 'Cd/Cm', 'Cd/WS', '% Code', 'Cd/File', 'Cm/File', 'WS/File'] \n",
      "\n",
      "['number_of_modules', 'lines_of_code', 'lines_of_code_per_module', 'McCabes_cyclomatic_complexity', 'McCabes_cyclomatic_complexity_per_module', 'lines_of_comment', 'lines_of_comment_per_module', 'lines_of_code_per_line_of_comment', 'McCabes_cyclomatic_complexity_per_line_of_comment', 'IF4', 'IF4_per_module', 'IF4_visible', 'IF4_visible_per_module', 'IF4_concrete', 'IF4_concrete', 'rejected_lines_of_code\\n'] \n",
      "\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print (codeAnalyzerHeader.split(',')[1:-1], \"\\n\")\n",
    "print (ccccHeader.split(';')[1:], \"\\n\")\n",
    "\n",
    "labels = ccccHeader.split(';')[1:] + codeAnalyzerHeader.split(',')[1:-1]\n",
    "\n",
    "print (len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12306, 29)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "(12306, 26)\n",
      "(5038, 26)\n",
      "['number_of_modules', 'lines_of_code', 'lines_of_code_per_module', 'McCabes_cyclomatic_complexity', 'McCabes_cyclomatic_complexity_per_module', 'lines_of_comment', 'lines_of_comment_per_module', 'lines_of_code_per_line_of_comment', 'McCabes_cyclomatic_complexity_per_line_of_comment', 'IF4', 'IF4_per_module', 'IF4_visible', 'IF4_visible_per_module', 'IF4_concrete', 'IF4_concrete', 'rejected_lines_of_code\\n', 'Files', 'Lines', 'AVG Len', 'Code', 'Comments', 'White SP', 'Cd/Cm+WS', 'Cd/Cm', 'Cd/WS', '% Code']\n"
     ]
    }
   ],
   "source": [
    "def enlist_kept_cols(X, labels):\n",
    "    \n",
    "    cnt_cols = X.shape[1]\n",
    "    X_reduced = []\n",
    "    #labels_reduced = []\n",
    "    kept_cols = []\n",
    "    \n",
    "    for i in range(cnt_cols):\n",
    "        col = X[:,i]\n",
    "        notInside = True\n",
    "        for j in range(len(X_reduced)):\n",
    "            if (col == X_reduced[j]).all():\n",
    "                notInside = False\n",
    "        \n",
    "        if notInside:\n",
    "            kept_cols.append(i)\n",
    "            #labels_reduced.append(labels[i])\n",
    "            X_reduced.append(col)\n",
    "\n",
    "    #return np.array(X_reduced).T, labels_reduced, kept_cols\n",
    "    return kept_cols\n",
    "\n",
    "#X, labels_reduced = remove_same_cols(X, labels)\n",
    "# decision on which column will be kept or not is made on training part because it is bigger\n",
    "kept_cols = enlist_kept_cols(X_train, labels)\n",
    "print (kept_cols)\n",
    "X_train_reduced = X_train[:, kept_cols]\n",
    "print (X_train_reduced.shape)\n",
    "X_test_reduced = X_test[:, kept_cols]\n",
    "print (X_test_reduced.shape)\n",
    "labels_reduced = [labels[i] for i in kept_cols]\n",
    "print (labels_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def create_json(author_names, dataset):\n",
    "    data = {}\n",
    "    data[\"column_descriptors\"] = labels_reduced\n",
    "    data[\"author_data\"] = {}\n",
    "    for author in author_names:\n",
    "        feature_vecs, scores = get_author_features_and_scores(author, dataset)\n",
    "        if len(scores) == 0:\n",
    "            continue\n",
    "        feat_vecs = [fv[kept_cols].tolist() for fv in feature_vecs]\n",
    "        author_data = {}\n",
    "        author_data[\"feature_vecs\"] = feat_vecs\n",
    "        author_data[\"scores\"] = scores\n",
    "        data[\"author_data\"][author] = author_data\n",
    "        \n",
    "    with open('dataset.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "#print get_author_features_and_scores(author_names[15], dataset)[1]\n",
    "create_json(author_names, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "def load_json():\n",
    "    \n",
    "    authors = []\n",
    "    features = []\n",
    "    scores = []\n",
    "    \n",
    "    with open('dataset.json') as data_file:\n",
    "        data = json.load(data_file)\n",
    "        labels = data[\"column_descriptors\"]\n",
    "        author_data = data[\"author_data\"]\n",
    "        \n",
    "        for author in author_data.keys():\n",
    "            authors.append(author)\n",
    "            features.append(author_data[author]['feature_vecs'])\n",
    "            scores_str = author_data[author]['scores']\n",
    "            scores.append(np.asarray([int(score_) for score_ in scores_str]))\n",
    "    \n",
    "    # features to numpy array\n",
    "    features = [np.asarray(feature) for feature in features]\n",
    "    \n",
    "    return labels, authors, features, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masscot (4, 26) (4,)\n",
      "['number_of_modules', 'lines_of_code', 'lines_of_code_per_module', 'McCabes_cyclomatic_complexity', 'McCabes_cyclomatic_complexity_per_module', 'lines_of_comment', 'lines_of_comment_per_module', 'lines_of_code_per_line_of_comment', 'McCabes_cyclomatic_complexity_per_line_of_comment', 'IF4', 'IF4_per_module', 'IF4_visible', 'IF4_visible_per_module', 'IF4_concrete', 'IF4_concrete', 'rejected_lines_of_code\\n', 'Files', 'Lines', 'AVG Len', 'Code', 'Comments', 'White SP', 'Cd/Cm+WS', 'Cd/Cm', 'Cd/WS', '% Code']\n"
     ]
    }
   ],
   "source": [
    "labels, authors, features, scores = load_json()\n",
    "print (authors[0], features[0].shape, scores[0].shape)\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n",
      "1095\n",
      "469\n"
     ]
    }
   ],
   "source": [
    "# training and test split\n",
    "import random\n",
    "cnt_train = 1095\n",
    "\n",
    "print (cnt_train)\n",
    "\n",
    "train_authors_indices = set()\n",
    "\n",
    "while len(train_authors_indices) < cnt_train:\n",
    "    train_authors_indices.add(random.randint(0, len(authors) - 1))\n",
    "    \n",
    "test_authors_indices = set()\n",
    "\n",
    "for i in range(len(authors)):\n",
    "    if i not in train_authors_indices:\n",
    "        test_authors_indices.add(i)\n",
    "\n",
    "train_authors = [authors[i] for i in train_authors_indices]\n",
    "        \n",
    "test_authors = [authors[i] for i in test_authors_indices]\n",
    "\n",
    "print(len(train_authors))\n",
    "print(len(test_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12257, 26) (12257,) (5087, 26) (5087,)\n"
     ]
    }
   ],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for index in train_authors_indices:\n",
    "    X_train_list.extend(features[index])\n",
    "    y_train_list.extend(scores[index])\n",
    "    \n",
    "for index in test_authors_indices:\n",
    "    X_test_list.extend(features[index])\n",
    "    y_test_list.extend(scores[index])\n",
    "\n",
    "X_train = np.asarray(X_train_list)\n",
    "y_train = np.asarray(y_train_list)\n",
    "X_test = np.asarray(X_test_list)\n",
    "y_test = np.asarray(y_test_list)\n",
    "\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5087, 26)\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#print 'labels', labels_reduced\n",
    "df_before_feature_sel = pd.DataFrame(X_test)\n",
    "#df_before_feature_sel.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "df_before_feature_sel.columns = [str(label).replace(' ', '_') for label in labels]\n",
    "print (df_before_feature_sel.shape)\n",
    "print (len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a8f11a2fdfb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df_before_feature_sel.columns = labels_reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_before_feature_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.5/site-packages/seaborn/linearmodels.py\u001b[0m in \u001b[0;36mpairplot\u001b[0;34m(data, hue, hue_order, palette, vars, x_vars, y_vars, kind, diag_kind, markers, size, aspect, dropna, plot_kws, diag_kws, grid_kws)\u001b[0m\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"scatter\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[0mplot_kws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"edgecolor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"white\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m         \u001b[0mplotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplot_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"reg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0mplotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplot_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.5/site-packages/seaborn/axisgrid.py\u001b[0m in \u001b[0;36mmap_offdiag\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \"\"\"\n\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_upper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.5/site-packages/seaborn/axisgrid.py\u001b[0m in \u001b[0;36mmap_lower\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                 \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkw_color\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mkw_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 func(data_k[x_var], data_k[y_var], label=label_k,\n\u001b[0;32m-> 1400\u001b[0;31m                      color=color, **kwargs)\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3256\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3257\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3258\u001b[0;31m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3259\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1818\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   3808\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3810\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This doesn't have to match x, y in size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#df_before_feature_sel.columns = labels_reduced\n",
    "sns.pairplot(df_before_feature_sel, size=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, label in enumerate(labels):\n",
    "    print (i, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_descriptions = df_before_feature_sel.describe()\n",
    "print (df_descriptions.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
