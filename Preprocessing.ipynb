{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0_14_16505_55.cpp,1,49,13,47,0,2,23.50,0.00,23.50,0.96,47,0,2\n",
      "\n",
      "0.0_14_16505_55.csv;1;43;43.000;12;12.000;0;0.000;******;******;0;0.000;0;0.000;0;0.000;3\n",
      "\n",
      "#file_name;cnt_classes;max_member_funs;max_nested_loops;max_nesting_depth;max_params_in_decl;member_funs;member_vars;min_member_funs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linesCodeAnalyzer = None\n",
    "with open('CodeJamCrawler/dataset_csvs/code_analyzer_out_sorted.csv', 'r') as f:\n",
    "    linesCodeAnalyzer = f.readlines()\n",
    "    \n",
    "codeAnalyzerHeader = linesCodeAnalyzer[0]\n",
    "linesCodeAnalyzer = linesCodeAnalyzer[1:]\n",
    "\n",
    "linesCccc = None\n",
    "with open('CodeJamCrawler/dataset_csvs/cccc_cleared.csv', 'r') as f:\n",
    "    linesCccc = f.readlines()\n",
    "    \n",
    "linesASTExtractor = None\n",
    "with open('ASTExtractor/ast_features.csv', 'r') as f:\n",
    "    linesASTExtractor = f.readlines()\n",
    "\n",
    "ASTExtractorHeader = linesASTExtractor[0]\n",
    "    \n",
    "ccccHeader = linesCccc[0]\n",
    "linesCccc = linesCccc[1:]\n",
    "linesASTExtractor = linesASTExtractor[1:]\n",
    "\n",
    "print (linesCodeAnalyzer[0])\n",
    "print (linesCccc[0])\n",
    "print (ASTExtractorHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def get_file_name(line, splitter):\n",
    "    entries = line.split(splitter)\n",
    "    file_name, file_ext = os.path.splitext(entries[0])\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0_14_16505_55\n",
      "0.0_14_16505_55\n",
      "0.0_14_16505_55\n"
     ]
    }
   ],
   "source": [
    "print (get_file_name(linesCodeAnalyzer[0], ','))\n",
    "print (get_file_name(linesCccc[0], ';'))\n",
    "print (get_file_name(linesASTExtractor[0], ';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "Number of cpp files: 18667\n"
     ]
    }
   ],
   "source": [
    "# removing all the entries that don't exist in outputCleared\n",
    "cpp_files_only = []\n",
    "for i in range(len(linesCodeAnalyzer)):\n",
    "    if i % 1000 == 0:\n",
    "        print (i)\n",
    "        \n",
    "    other = linesCodeAnalyzer[i]\n",
    "    file_name_other = get_file_name(other, ',')\n",
    "    \n",
    "    found = False\n",
    "    for cleared in linesCccc:\n",
    "        file_name_cleared = get_file_name(cleared, ';')\n",
    "        if file_name_cleared == file_name_other:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        continue\n",
    "    cpp_files_only.append(file_name_other)\n",
    "    \n",
    "print (\"Number of cpp files:\", len(cpp_files_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0_14_16505_55\n"
     ]
    }
   ],
   "source": [
    "print (cpp_files_only[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code analyzer output: #File Name,Files,Lines,AVG Len,Code,Comments,White SP,Cd/Cm+WS,Cd/Cm,Cd/WS,% Code,Cd/File,Cm/File,WS/File,\n",
      "\n",
      "CCCC analyzer output: #filename;number_of_modules;lines_of_code;lines_of_code_per_module;McCabes_cyclomatic_complexity;McCabes_cyclomatic_complexity_per_module;lines_of_comment;lines_of_comment_per_module;lines_of_code_per_line_of_comment;McCabes_cyclomatic_complexity_per_line_of_comment;IF4;IF4_per_module;IF4_visible;IF4_visible_per_module;IF4_concrete;IF4_concrete;rejected_lines_of_code\n",
      "\n",
      "ASTExtractor output: #file_name;cnt_classes;max_member_funs;max_nested_loops;max_nesting_depth;max_params_in_decl;member_funs;member_vars;min_member_funs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Code analyzer output:', codeAnalyzerHeader)\n",
    "print ('CCCC analyzer output:', ccccHeader)\n",
    "print ('ASTExtractor output:', ASTExtractorHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_cccc(cccc_line):\n",
    "    name = get_file_name(cccc_line, ';')\n",
    "    res = name.split('_')[-1]\n",
    "    author = name\n",
    "    features = []\n",
    "    for num in cccc_line.split(';')[1:]:\n",
    "        if num == '******' or num == '------':\n",
    "            num = '0.0'\n",
    "        try:\n",
    "            features.append(float(num))\n",
    "        except ValueError:\n",
    "            print (num)\n",
    "            break\n",
    "    return author, features, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_code_analyzer(code_anal_line):\n",
    "    name = get_file_name(code_anal_line, ',')\n",
    "    res = name.split('_')[-1]\n",
    "    author = name\n",
    "    features = []\n",
    "    for num in code_anal_line.split(',')[1:]:\n",
    "        try:\n",
    "            features.append(float(num))\n",
    "        except ValueError:\n",
    "            print (num)\n",
    "            break\n",
    "    return author, features, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_ast_extractor(code_extractor_line):\n",
    "    name = get_file_name(code_extractor_line, ';')\n",
    "    res = name.split('_')[-1]\n",
    "    author = name#.split('_')[0]\n",
    "    features = []\n",
    "    for num in code_extractor_line.split(';')[1:]:\n",
    "        try:\n",
    "            features.append(float(num))\n",
    "        except ValueError:\n",
    "            print (num)\n",
    "            break\n",
    "    return author, features, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cccc line vec ('0.0_14_16505_55', [1.0, 43.0, 43.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], '55')\n",
      "code line vec ('0.0_14_16505_55', [1.0, 49.0, 13.0, 47.0, 0.0, 2.0, 23.5, 0.0, 23.5, 0.96, 47.0, 0.0, 2.0], '55')\n",
      "ast line vec ('0.0_14_16505_55', [0.0, 0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 150000.0], '55')\n"
     ]
    }
   ],
   "source": [
    "print ('cccc line vec', parse_cccc(linesCccc[0]))\n",
    "print ('code line vec', parse_code_analyzer(linesCodeAnalyzer[0]))\n",
    "print ('ast line vec', parse_ast_extractor(linesASTExtractor[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18667 18667 18667\n"
     ]
    }
   ],
   "source": [
    "cpp_files_map = set()\n",
    "\n",
    "for n in cpp_files_only:\n",
    "    cpp_files_map.add(n)\n",
    "\n",
    "src_file_vec_map = {}\n",
    "\n",
    "for cccc_line in linesCccc:\n",
    "    name, features, res = parse_cccc(cccc_line)\n",
    "    if name not in src_file_vec_map and name in cpp_files_map:\n",
    "        src_file_vec_map[name] = [(features,res)]\n",
    "    elif name in cpp_files_map:\n",
    "        src_file_vec_map[name].append((features, res))\n",
    "\n",
    "for code_anal_line in linesCodeAnalyzer:\n",
    "    name, features, res = parse_code_analyzer(code_anal_line)\n",
    "    if name in cpp_files_map:\n",
    "        src_file_vec_map[name].append((features, res))\n",
    "\n",
    "i = 0\n",
    "for ast_line in linesASTExtractor:\n",
    "    name, features, res = parse_ast_extractor(ast_line)\n",
    "    if name in cpp_files_map:\n",
    "        src_file_vec_map[name].append((features, res))\n",
    "        i += 1\n",
    "        \n",
    "print (i, len(cpp_files_only), len(cpp_files_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_author_name(file_name):\n",
    "    return file_name.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_vec_map = {}\n",
    "\n",
    "for key in src_file_vec_map.keys():\n",
    "    v1 = src_file_vec_map[key][0]\n",
    "    v2 = src_file_vec_map[key][1]\n",
    "    v3 = src_file_vec_map[key][2]\n",
    "    author = get_author_name(key)\n",
    "    \n",
    "    if author not in src_vec_map.keys():\n",
    "        src_vec_map[author] = [(v1,v2,v3)]\n",
    "    else:\n",
    "        src_vec_map[author].append((v1, v2, v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1822\n",
      "Number of samples:  18667\n"
     ]
    }
   ],
   "source": [
    "print (len(src_vec_map))\n",
    "\n",
    "sample_count = 0\n",
    "for k in src_vec_map:\n",
    "    sample_count += len(src_vec_map[k])\n",
    "    \n",
    "print (\"Number of samples: \", sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def load_dataset(src_vec_map):\n",
    "    dataset_list = []\n",
    "    \n",
    "    for k in src_vec_map:\n",
    "        for i in range(len(src_vec_map[k])):\n",
    "            label = src_vec_map[k][i][0][1]\n",
    "            l1 = np.asarray(src_vec_map[k][i][0][0])\n",
    "            l2 = np.asarray(src_vec_map[k][i][1][0])\n",
    "            l3 = np.asarray(src_vec_map[k][i][2][0])\n",
    "            l = np.concatenate((l1, l2), axis=0)\n",
    "            l = np.concatenate((l, l3), axis=0)\n",
    "            dataset_list.append((l, (k, label)))\n",
    "    dataset = np.array(dataset_list)\n",
    "    dataset = dataset.reshape((dataset.shape[0], dataset.shape[1]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18667, 2)\n",
      "[ array([  1.00000000e+00,   5.80000000e+01,   5.80000000e+01,\n",
      "         3.20000000e+01,   3.20000000e+01,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         2.00000000e+00,   1.00000000e+00,   9.00000000e+01,\n",
      "         1.70000000e+01,   7.40000000e+01,   0.00000000e+00,\n",
      "         1.60000000e+01,   4.62000000e+00,   0.00000000e+00,\n",
      "         4.62000000e+00,   8.20000000e-01,   7.40000000e+01,\n",
      "         0.00000000e+00,   1.60000000e+01,   0.00000000e+00,\n",
      "         0.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n",
      "         2.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         1.50000000e+05])\n",
      " ('mrsud', '60')]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(src_vec_map)\n",
    "print (dataset.shape)\n",
    "print (dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_author_features_and_scores(author_name, dataset):\n",
    "    codes = []\n",
    "    scores = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        if item[1][0] == author_name:\n",
    "            codes.append(item[0])\n",
    "            scores.append(item[1][1])\n",
    "            \n",
    "    return (codes, scores)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_names = list(src_vec_map.keys())\n",
    "X_list = []\n",
    "\n",
    "for author in author_names:\n",
    "    codes, scores = get_author_features_and_scores(author, dataset)\n",
    "    X_list.extend(codes)\n",
    "    \n",
    "X = np.asarray(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Files', 'Lines', 'AVG Len', 'Code', 'Comments', 'White SP', 'Cd/Cm+WS', 'Cd/Cm', 'Cd/WS', '% Code', 'Cd/File', 'Cm/File', 'WS/File'] \n",
      "\n",
      "['number_of_modules', 'lines_of_code', 'lines_of_code_per_module', 'McCabes_cyclomatic_complexity', 'McCabes_cyclomatic_complexity_per_module', 'lines_of_comment', 'lines_of_comment_per_module', 'lines_of_code_per_line_of_comment', 'McCabes_cyclomatic_complexity_per_line_of_comment', 'IF4', 'IF4_per_module', 'IF4_visible', 'IF4_visible_per_module', 'IF4_concrete', 'IF4_concrete', 'rejected_lines_of_code\\n'] \n",
      "\n",
      "['cnt_classes', 'max_member_funs', 'max_nested_loops', 'max_nesting_depth', 'max_params_in_decl', 'member_funs', 'member_vars']\n",
      "\n",
      "Total label length before clearing: 37\n"
     ]
    }
   ],
   "source": [
    "print (codeAnalyzerHeader.split(',')[1:-1], \"\\n\")\n",
    "print (ccccHeader.split(';')[1:], \"\\n\")\n",
    "print (ASTExtractorHeader.split(';')[1:-1])\n",
    "labels = ccccHeader.split(';')[1:] + codeAnalyzerHeader.split(',')[1:-1] + ASTExtractorHeader.split(';')[1:]\n",
    "\n",
    "print (\"\\nTotal label length before clearing:\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 36] \n",
      "\n",
      "(18667, 34) \n",
      "\n",
      "['number_of_modules', 'lines_of_code', 'lines_of_code_per_module', 'McCabes_cyclomatic_complexity', 'McCabes_cyclomatic_complexity_per_module', 'lines_of_comment', 'lines_of_comment_per_module', 'lines_of_code_per_line_of_comment', 'McCabes_cyclomatic_complexity_per_line_of_comment', 'IF4', 'IF4_per_module', 'IF4_visible', 'IF4_visible_per_module', 'IF4_concrete', 'IF4_concrete', 'rejected_lines_of_code\\n', 'Files', 'Lines', 'AVG Len', 'Code', 'Comments', 'White SP', 'Cd/Cm+WS', 'Cd/Cm', 'Cd/WS', '% Code', 'cnt_classes', 'max_member_funs', 'max_nested_loops', 'max_nesting_depth', 'max_params_in_decl', 'member_funs', 'member_vars', 'min_member_funs\\n']\n"
     ]
    }
   ],
   "source": [
    "def enlist_kept_cols(X, labels):\n",
    "    cnt_cols = X.shape[1]\n",
    "    X_reduced = []\n",
    "    kept_cols = []\n",
    "    \n",
    "    for i in range(cnt_cols):\n",
    "        col = X[:,i]\n",
    "        notInside = True\n",
    "        for j in range(len(X_reduced)):\n",
    "            if (col == X_reduced[j]).all():\n",
    "                notInside = False\n",
    "        \n",
    "        if notInside:\n",
    "            kept_cols.append(i)\n",
    "            X_reduced.append(col)\n",
    "\n",
    "    return kept_cols\n",
    "\n",
    "kept_cols = enlist_kept_cols(X, labels)\n",
    "print (kept_cols, \"\\n\")\n",
    "\n",
    "X_reduced = X[:, kept_cols]\n",
    "print (X_reduced.shape, \"\\n\")\n",
    "\n",
    "labels_reduced = [labels[i] for i in kept_cols]\n",
    "print (labels_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def create_json(author_names, dataset):\n",
    "    data = {}\n",
    "    data[\"column_descriptors\"] = labels_reduced\n",
    "    data[\"author_data\"] = {}\n",
    "    for author in author_names:\n",
    "        feature_vecs, scores = get_author_features_and_scores(author, dataset)\n",
    "        if len(scores) == 0:\n",
    "            continue\n",
    "        feat_vecs = [fv[kept_cols].tolist() for fv in feature_vecs]\n",
    "        author_data = {}\n",
    "        author_data[\"feature_vecs\"] = feat_vecs\n",
    "        author_data[\"scores\"] = scores\n",
    "        data[\"author_data\"][author] = author_data\n",
    "        \n",
    "    with open('dataset.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "#print get_author_features_and_scores(author_names[15], dataset)[1]\n",
    "create_json(author_names, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
