{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "def load_json():\n",
    "    \n",
    "    authors = []\n",
    "    features = []\n",
    "    scores = []\n",
    "    \n",
    "    with open('dataset.json') as data_file:\n",
    "        data = json.load(data_file)\n",
    "        labels = data[\"column_descriptors\"]\n",
    "        author_data = data[\"author_data\"]\n",
    "        \n",
    "        for author in author_data.keys():\n",
    "            authors.append(author)\n",
    "            features.append(author_data[author]['feature_vecs'])\n",
    "            scores_str = author_data[author]['scores']\n",
    "            scores.append(np.asarray([int(score_) for score_ in scores_str]))\n",
    "    \n",
    "    # features to numpy array\n",
    "    features = [np.asarray(feature) for feature in features]\n",
    "    \n",
    "    return labels, authors, features, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels, authors, features, scores = load_json()\n",
    "print (authors[0], features[0].shape, scores[0].shape)\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training and test split\n",
    "import random\n",
    "cnt_train = 0.7 * len(authors) + 1\n",
    "\n",
    "print (cnt_train)\n",
    "\n",
    "train_authors_indices = set()\n",
    "\n",
    "while len(train_authors_indices) < cnt_train:\n",
    "    train_authors_indices.add(random.randint(0, len(authors) - 1))\n",
    "    \n",
    "test_authors_indices = set()\n",
    "\n",
    "for i in range(len(authors)):\n",
    "    if i not in train_authors_indices:\n",
    "        test_authors_indices.add(i)\n",
    "\n",
    "train_authors = [authors[i] for i in train_authors_indices]\n",
    "        \n",
    "test_authors = [authors[i] for i in test_authors_indices]\n",
    "\n",
    "print(len(train_authors))\n",
    "print(len(test_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for index in train_authors_indices:\n",
    "    X_train_list.extend(features[index])\n",
    "    y_train_list.extend(scores[index])\n",
    "    \n",
    "for index in test_authors_indices:\n",
    "    X_test_list.extend(features[index])\n",
    "    y_test_list.extend(scores[index])\n",
    "\n",
    "X_train = np.asarray(X_train_list)\n",
    "y_train = np.asarray(y_train_list)\n",
    "X_test = np.asarray(X_test_list)\n",
    "y_test = np.asarray(y_test_list)\n",
    "\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y is vector of labels\n",
    "def create_labels(y):\n",
    "    y_l = np.copy(y)\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] >= 80: \n",
    "            y_l[i] = 5\n",
    "        if y[i] >= 60 and y[i] < 80: \n",
    "            y_l[i] = 4\n",
    "        if y[i] >= 40 and y[i] < 60:\n",
    "            y_l[i] = 3\n",
    "        if y[i] >= 20 and y[i] < 40:\n",
    "            y_l[i] = 2\n",
    "        if y[i] < 20: \n",
    "            y_l[i] = 1\n",
    "    return y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_labeled = create_labels(y_train)\n",
    "y_test_labeled = create_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_features='log2')\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "print (rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "print (clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print (clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import multiprocessing\n",
    "cores=multiprocessing.cpu_count()-2\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 100, 1000]}\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters, n_jobs=cores, verbose=2)\n",
    "clf.fit(X_train, y_train)\n",
    "print (clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "print (gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train, y_train)\n",
    "print (abc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(n_estimators=30)\n",
    "etc.fit(X_train, y_train)\n",
    "print (etc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print X.shape, y.reshape((y.shape[0], 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = X#np.concatenate((X, y.T), axis=1)\n",
    "\n",
    "dataset = np.concatenate((X,y[:,None]),axis=1)\n",
    "#print X.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset)\n",
    "#sns.pairplot(df)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
