{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def printf(format, *args):\n",
    "    sys.stdout.write(format % args)\n",
    "    \n",
    "def load_json():\n",
    "    \n",
    "    authors = []\n",
    "    features = []\n",
    "    scores = []\n",
    "    \n",
    "    with open('dataset.json') as data_file:\n",
    "        data = json.load(data_file)\n",
    "        labels = data[\"column_descriptors\"]\n",
    "        author_data = data[\"author_data\"]\n",
    "        \n",
    "        for author in author_data.keys():\n",
    "            authors.append(author)\n",
    "            features.append(author_data[author]['feature_vecs'])\n",
    "            scores_str = author_data[author]['scores']\n",
    "            scores.append(np.asarray([int(score_) for score_ in scores_str]))\n",
    "    \n",
    "    features = [np.asarray(feature) for feature in features]\n",
    "    \n",
    "    return labels, authors, features, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tommy (5, 34) (5,) \n",
      "\n",
      "['number_of_modules', 'lines_of_code', 'lines_of_code_per_module', 'McCabes_cyclomatic_complexity', 'McCabes_cyclomatic_complexity_per_module', 'lines_of_comment', 'lines_of_comment_per_module', 'lines_of_code_per_line_of_comment', 'McCabes_cyclomatic_complexity_per_line_of_comment', 'IF4', 'IF4_per_module', 'IF4_visible', 'IF4_visible_per_module', 'IF4_concrete', 'IF4_concrete', 'rejected_lines_of_code\\n', 'Files', 'Lines', 'AVG Len', 'Code', 'Comments', 'White SP', 'Cd/Cm+WS', 'Cd/Cm', 'Cd/WS', '% Code', 'cnt_classes', 'max_member_funs', 'max_nested_loops', 'max_nesting_depth', 'max_params_in_decl', 'member_funs', 'member_vars', 'min_member_funs\\n']\n"
     ]
    }
   ],
   "source": [
    "labels, authors, features, scores = load_json()\n",
    "print (authors[0], features[0].shape, scores[0].shape, \"\\n\")\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y is vector of labels\n",
    "def create_labels(y):\n",
    "    y_l = np.copy(y)\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] >= 80: \n",
    "            y_l[i] = 5\n",
    "        if y[i] >= 60 and y[i] < 80: \n",
    "            y_l[i] = 4\n",
    "        if y[i] >= 40 and y[i] < 60:\n",
    "            y_l[i] = 3\n",
    "        if y[i] >= 20 and y[i] < 40:\n",
    "            y_l[i] = 2\n",
    "        if y[i] < 20: \n",
    "            y_l[i] = 1\n",
    "    return y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training and test split\n",
    "import random\n",
    "def createTrainTestSplit():\n",
    "    cnt_train = int(0.8 * len(authors)) + 1\n",
    "\n",
    "    train_authors_indices = set()\n",
    "\n",
    "    while len(train_authors_indices) < cnt_train:\n",
    "        train_authors_indices.add(random.randint(0, len(authors) - 1))\n",
    "\n",
    "    test_authors_indices = set()\n",
    "\n",
    "    for i in range(len(authors)):\n",
    "        if i not in train_authors_indices:\n",
    "            test_authors_indices.add(i)\n",
    "\n",
    "    train_authors = [authors[i] for i in train_authors_indices]\n",
    "\n",
    "    test_authors = [authors[i] for i in test_authors_indices]\n",
    "    \n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    X_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    for index in train_authors_indices:\n",
    "        X_train_list.extend(features[index])\n",
    "        y_train_list.extend(scores[index])\n",
    "\n",
    "    for index in test_authors_indices:\n",
    "        X_test_list.extend(features[index])\n",
    "        y_test_list.extend(scores[index])\n",
    "\n",
    "    X_train = np.asarray(X_train_list)\n",
    "    y_train = np.asarray(y_train_list)\n",
    "    X_test = np.asarray(X_test_list)\n",
    "    y_test = np.asarray(y_test_list)\n",
    "    \n",
    "    y_train = create_labels(y_train) \n",
    "    y_test = create_labels(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = createTrainTestSplit()\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print (clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train, y_train)\n",
    "print (abc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "print (gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(n_estimators=30)\n",
    "etc.fit(X_train, y_train)\n",
    "print (etc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "print (dtc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, tree_.value[node]))\n",
    "\n",
    "    recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_to_code(dtc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1]\n",
    "solvers = [\"adam\", \"lbfgs\", \"sgd\"]\n",
    "learning_rates = [\"constant\", \"adaptive\", \"invscaling\"]\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha:\\t\", alpha)\n",
    "    for solver in solvers:\n",
    "        printf(\"Solver:\\t%s\\n\", solver)\n",
    "        for learning_rate in learning_rates:\n",
    "            for i in range(0, 5):\n",
    "                X_train, y_train, X_test, y_test = createTrainTestSplit()\n",
    "                printf(\"Train/test split number %d\\n\", i)\n",
    "                printf(\"\\tLearning rate:\\t%s\\n\", learning_rate)\n",
    "                mlpC = MLPClassifier(alpha=alpha, batch_size='auto', learning_rate=learning_rate, learning_rate_init=0.01, power_t=0.5, shuffle=True, max_iter=500)\n",
    "                mlpC.fit(X_train, y_train)\n",
    "                printf(\"\\tMLPC Score:\\t%f\\n\\n\", mlpC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "criterions = [ \"gini\", \"entropy\"]\n",
    "estimators_size = [50, 100, 150, 200]\n",
    "\n",
    "for criterion in criterions:\n",
    "    for n_estimators in estimators_size:\n",
    "        values = []\n",
    "        printf(\"RFC\\t%d estimators\\t%s criterion\\n\", n_estimators, criterion)\n",
    "        for i in range(0, 5):\n",
    "            X_train, y_train, X_test, y_test = createTrainTestSplit()\n",
    "            rfc = RandomForestClassifier(n_estimators=n_estimators, max_features='log2', criterion=criterion)\n",
    "            rfc.fit(X_train, y_train)\n",
    "            values.append(rfc.score(X_test, y_test))\n",
    "        \n",
    "        values.sort()\n",
    "        print(\"Median:\", values[2])\n",
    "        print(\"Average:\", sum(values) / 5)\n",
    "        print(\"Min:\", min(values))\n",
    "        print(\"Max:\", max(values))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
